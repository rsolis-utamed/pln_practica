{"cells":[{"cell_type":"markdown","source":["#1. Instalación / importación de librerías"],"metadata":{"id":"AWgl0uQnj_qO"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Zu19PjMKX_YM","executionInfo":{"status":"ok","timestamp":1768327424932,"user_tz":-60,"elapsed":17289,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"}}},"outputs":[],"source":["# Ejecuta esta celda PRIMERO\n","!pip install -q -U langchain==0.3.0 langchain-community==0.3.0 langchain-google-genai==2.0.0 langchainhub==0.1.20 pysentimiento joblib google-generativeai"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"yG9LK-uzGuld","executionInfo":{"status":"ok","timestamp":1768327424947,"user_tz":-60,"elapsed":5,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"}}},"outputs":[],"source":["#!pip install --upgrade -q google-generativeai langchain-google-genai"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1768327424967,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"ZFnnce3wYedt","outputId":"dc3526f9-033f-4e7f-ad45-d65e6ca72b7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Versión cargada: 0.3.0\n"]}],"source":["import langchain\n","print(f\"Versión cargada: {langchain.__version__}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19386,"status":"ok","timestamp":1768327444354,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"p_qUbKF2YD3S","outputId":"0b528e1a-82bd-45d1-a01c-df8e1f5450ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting es-core-news-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('es_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}],"source":["# 2. Descargar modelo de Spacy\n","!python -m spacy download es_core_news_sm"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"yjmiIiE3NRmq","executionInfo":{"status":"ok","timestamp":1768327461235,"user_tz":-60,"elapsed":16877,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"}}},"outputs":[],"source":["import nltk # PLN\n","import spacy # Lemantización\n","from langchain_google_genai import ChatGoogleGenerativeAI # Nos permite utilizar un modelo de IA generativa de Google\n","from langchain.tools import tool #Importa el decorador para manipular funciones para el agente LangChain\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder # Nos permite definir instrucciones a considerar en el chat\n","from langchain_core.messages import HumanMessage, SystemMessage # Nos permite definir el contenido para el rol del sistema y el mensaje de usuario\n","from langchain.agents import create_react_agent, AgentExecutor # Importar la clase AgentExecutor\n","from langchain import hub # Nos permite descargar modelos pre-entrenados\n","import joblib # Librería para guardar modelos entrenados\n","from google.colab import files # Librería para descargar archivos generados\n","import sys # Manipulación de pahts\n","from google.colab import userdata # Llamada de secretos\n"]},{"cell_type":"markdown","source":["#2. Descarga del repositorio github"],"metadata":{"id":"TcOpPATvkMcz"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116,"status":"ok","timestamp":1768327461354,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"1JZZ2oE3lOTH","outputId":"ac1d2bc3-fdf7-4066-c13d-aa24e9bd6f5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'pln_practica' already exists and is not an empty directory.\n"]}],"source":["# Desargamos el respositorio donde tenemos el código (Lo vamos a emplear para ejecutar la clase Preprocessor.py)\n","!git clone https://github.com/rsolis-utamed/pln_practica.git"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1768327461811,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"wFuf7IEQlSkO","outputId":"39516f12-284d-465f-91e9-35f06b1032ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Already up to date.\n"]}],"source":["#Actualizamos el el contenido del repositorio (si procede)\n","!cd /content/pln_practica && git pull"]},{"cell_type":"markdown","source":["#3. Definición de paths y descarga de modelos generados y script de procesamiento en el notebook \"modelado\""],"metadata":{"id":"py2jct5lkRxM"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"aKRiStQ2lfZ9","executionInfo":{"status":"ok","timestamp":1768327461824,"user_tz":-60,"elapsed":14,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"}}},"outputs":[],"source":["# Definimos un path para poder trabajar con scripts python subidos al respositorio\n","sys.path.append('/content/pln_practica/code')\n","sys.path.append('/content/pln_practica/models')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"4as0ijbknnGl","executionInfo":{"status":"ok","timestamp":1768327461829,"user_tz":-60,"elapsed":3,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"}}},"outputs":[],"source":["\n","clf_textb_sent = joblib.load('/content/pln_practica/models/text_blob_model.joblib')\n","cld_lda_topics = joblib.load('/content/pln_practica/models/lda_topics_model.joblib')\n","vectorizer = joblib.load('/content/pln_practica/models/vectorizador_tfidf.joblib')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":122,"status":"ok","timestamp":1768327461952,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"xxgc0S8EoUCC","outputId":"42604bd2-9b52-4a98-cab3-312bd84b5b5f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}],"source":["# Descargar recursos de NLTK necesarios\n","nltk.download('punkt') # Recurso encargado de tokenizar (división del texto en unidades más pequeñas, normalmente palabras)\n","nltk.download('stopwords') # Recurso que contiene palabras muy comunes que no aportan significado temático por sí solas.\n","nltk.download('punkt_tab') # Recurso que asegura la compatibilidad del sistema de división de palabras y frases."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"S-DgWcRRnuyL","executionInfo":{"status":"ok","timestamp":1768327463553,"user_tz":-60,"elapsed":1596,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"}}},"outputs":[],"source":["# Ejecutar en terminal antes: python -m spacy download es_core_news_sm\n","try:\n","    nlp = spacy.load(\"es_core_news_sm\") # Descargamos un modelo pre-entrenado en español\n","except:\n","    print(\"Spacy model non found. Execute: python -m spacy download es_core_news_sm\")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"l3czOhzHMk6-","executionInfo":{"status":"ok","timestamp":1768327463584,"user_tz":-60,"elapsed":17,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"}}},"outputs":[],"source":["# Palabras encontradas en topicos generados anteriormente (en pruebas previas) que se ha considearo que no aportan valor. Se incorporan dentro de\n","# el resto de stopwords\n","ruido_nuevo = ['él', 'decir', 'dejar', 'cada', 'dar', 'año', 'pasar','alguno', 'claro', 'igual', 'siempre', 'vez', 'medio']"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1768327463602,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"bTAS-IJBnL7Z","outputId":"1c379559-b0b2-4cee-9b22-acdef7ca611b"},"outputs":[{"output_type":"stream","name":"stdout","text":["version 2.1.0\n"]}],"source":["# Importamos la clase propia preprocessor del reposistorio github\n","from Preprocessor import Preprocessor\n","preprocesador=Preprocessor(nlp,ruido_nuevo)\n"]},{"cell_type":"markdown","source":["# 4. Definición de funciones que encapsulan la llamada de los modelos"],"metadata":{"id":"WWDGYVfTkkTh"}},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":61,"status":"ok","timestamp":1768327463679,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"iVWoh9lOId0O"},"outputs":[],"source":["\n","@tool\n","def det_sentimiento(text: str) -> str:\n","    \"\"\"\n","    Analiza el sentimiento de un texto dado (positivo, negativo, neutro).\n","    Utiliza el modelo de análisis de sentimiento pre-entrenado cargado como 'clf_textb_sent'.\n","    \"\"\"\n","    try:\n","        preprocessed_text = preprocesador.toPreprocessText(text)\n","        vec_text = vectorizer.transform([preprocessed_text])[0]\n","\n","        if not preprocessed_text:\n","            return \"No se pudo procesar el texto para análisis de sentimiento. El texto preprocesado resultó vacío o nulo.\"\n","        sentiment_prediction = clf_textb_sent.predict([vec_text])\n","        return f\"El sentimiento del texto es: {sentiment_prediction}\"\n","    except Exception as e:\n","        return f\"Error al analizar el sentimiento: {e}\"\n","\n","@tool\n","def det_topic(text: str) -> str:\n","    \"\"\"\n","    Identifica el tópico principal de un texto dado.\n","    Utiliza el modelo LDA de tópicos cargado como 'cld_lda_topics' y el vectorizador TF-IDF 'vectorizer'.\n","    \"\"\"\n","    try:\n","        preprocessed_text = preprocesador.toPreprocessText(text)\n","\n","        if not preprocessed_text:\n","            return \"No se pudo procesar el texto para análisis de tópicos. El texto preprocesado resultó vacío o nulo.\"\n","        text_vectorized = vectorizer.transform([preprocessed_text])\n","        topic_distribution = cld_lda_topics.transform(text_vectorized)[0]\n","        dominant_topic_idx = np.argmax(topic_distribution)\n","\n","        # Nota: Los nombres de los tópicos no están definidos en el contexto actual,\n","        # así que se devuelve el índice del tópico dominante y su probabilidad.\n","        return f\"El tópico principal del texto es el Tópico {dominant_topic_idx} con una probabilidad de {topic_distribution[dominant_topic_idx]:.2f}\"\n","    except Exception as e:\n","        return f\"Error al analizar los tópicos: {e}\""]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1768327463704,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"JGzhMbOIIve3"},"outputs":[],"source":["tools=[det_sentimiento,det_topic]"]},{"cell_type":"markdown","source":["# 5. Definición de agente LangChain y llamada de modelo llm de google gemini"],"metadata":{"id":"xvdJ3mAEkrYJ"}},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":813,"status":"ok","timestamp":1768327464518,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"DTl-qZp34sht"},"outputs":[],"source":["GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":64,"status":"ok","timestamp":1768327464597,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"lq2i0UG_MtNY"},"outputs":[],"source":["# Definimos el LLM (Google Gemini)\n","llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",\n","                             temperature=0.7,\n","                             top_p=0.85,\n","                             google_api_key=GOOGLE_API_KEY,\n","                             version=\"v1\"\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1768327464618,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"sKJJVdc9sKds"},"outputs":[],"source":["# 2. Definir el Rol y las Instrucciones (Prompt)\n","instrucciones_sistema =\"\"\"Eres un Asistente Especialista en Análisis de Opiniones de la ciudad de Málaga.\n","Tu única misión es clasificar el SENTIMIENTO y el TÓPICO, empleando las funciones propias {tools}, de los mensajes que te den.\n","\n","REGLAS CRÍTICAS:\n","1. Solo puedes responder preguntas relacionadas con el análisis de los textos proporcionados.\n","2. Si el usuario te pregunta sobre recetas, política general, o temas que no sean analizar mensajes,\n","   responde educadamente: 'Lo siento, como analista de opiniones de Málaga, solo puedo ayudarte con el sentimiento y tópicos de mensajes'.\n","3. Siempre usa las herramientas proporcionadas para dar una respuesta técnica basada en los modelos .joblib.\"\"\""]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1768327464635,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"QX10v9LnGtwH"},"outputs":[],"source":["\n","#D Definimos la plantilla para el prompt\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", instrucciones_sistema),\n","    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n","    (\"human\", \"{input}\"),  # Variable principal\n","    MessagesPlaceholder(variable_name=\"agent_scratchpad\"), # Espacio para que el agente piense\n","])"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":316,"status":"ok","timestamp":1768327464965,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"IbFJ1SYl7ieR","outputId":"bf4009c4-ed4b-462c-877c-77bed62ff7f8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n","  warnings.warn(\n"]}],"source":["prompt = hub.pull(\"hwchase17/react\")"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1768327465013,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"AFQRLgJtTbZx"},"outputs":[],"source":["# Creamos un agente al que le pasamos el modelo llm, los modelos propios para polaridad y tópicos y la plantilla de prompt\n","agent=create_react_agent(llm,tools,prompt)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1768327465016,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"},"user_tz":-60},"id":"q82RdjOOcVgG"},"outputs":[],"source":["# Creamos el Ejecutor (El cuerpo que mueve al agente)\n","agent_executor = AgentExecutor(\n","    agent=agent,\n","    tools=tools,\n","    verbose=True, # Ponemos True para ver cómo piensa\n","    handle_parsing_errors=True\n",")"]},{"cell_type":"code","source":["input_chat=\"El servicio de autobuses es terrible y el conductor fue grosero\"\n"],"metadata":{"id":"DnDAzwiLgcj1","executionInfo":{"status":"ok","timestamp":1768327942938,"user_tz":-60,"elapsed":18,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Ejecución del agente que devuelve la polaridad y clasificación del tópico en función del texto pasado como prompt\n","agent_executor.invoke({\"input\": input_chat})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pylZfJ29TA_V","executionInfo":{"status":"ok","timestamp":1768327970563,"user_tz":-60,"elapsed":8066,"user":{"displayName":"Rafael Solís López","userId":"05807129043108867934"}},"outputId":"5edeef00-21f1-4999-b0b4-1e46eba2d87d"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mAction: det_sentimiento\n","Action Input: El servicio de autobuses es terrible y el conductor fue grosero\u001b[0m   Parsing to lower...\n","   Applying regular expresions...\n","   Tokenizing text...\n","   Lemmantizing text...\n","   Deleting stop words in text...\n","\u001b[36;1m\u001b[1;3mError al analizar el sentimiento: Expected 2D array, got 1D array instead:\n","array=[<Compressed Sparse Row sparse matrix of dtype 'float64'\n"," \twith 1 stored elements and shape (1, 210)>            ].\n","Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\u001b[0m\u001b[32;1m\u001b[1;3mThought: The `det_sentimiento` tool failed with an internal error related to array reshaping. This indicates that the tool is not correctly preparing the input for its underlying sentiment analysis model. As `det_sentimiento` is the only tool available for sentiment analysis, and it is not functioning correctly for the given input, I cannot determine the sentiment to answer the question. I must report that the tool failed.\n","Final Answer: No se puede determinar el sentimiento debido a un error interno en la herramienta `det_sentimiento`. La herramienta falló con el mensaje: \"Expected 2D array, got 1D array instead: array=[<Compressed Sparse Row sparse matrix of dtype 'float64' with 1 stored elements and shape (1, 210)> ]. Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\"\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'El servicio de autobuses es terrible y el conductor fue grosero',\n"," 'output': 'No se puede determinar el sentimiento debido a un error interno en la herramienta `det_sentimiento`. La herramienta falló con el mensaje: \"Expected 2D array, got 1D array instead: array=[<Compressed Sparse Row sparse matrix of dtype \\'float64\\' with 1 stored elements and shape (1, 210)> ]. Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\"'}"]},"metadata":{},"execution_count":29}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOTeQOdh29ZLZ52Dcm3pwcz"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}